上节提到，one-hot、词袋模型、TF-IDF算法等文本表示方法都存在共同的缺点为无法理解语言。通过这些方法表达出的词向量在计算出相似度之后，意思相关相似的词无法表现出更高。
##### 主要有两个缺点：

1.没有语义相似度
2.sparsity

为克服以上的缺点，提出了词向量的分布式表示。
#### Distributed representation词向量表示

分布式表示（distributed representation），描述的是把文本分散嵌入到另一个空间，一般从是从高维空间嵌入到低维空间。如何在低维空间表达一个词呢？目前流行的是通过矩阵降维或神经网络降维将语义分散存储到向量的各个维度中，这两类方法得到的向量空间是低维的一般都可以称作分布式表示，又称为词嵌入（word embedding）或词向量）。
这种方法为深度学习在NLP领域的一个应用。

分布式表示的方法基本假设为：上下文相似的词，其语义也相似。而基本思路是通过训练将每个词映射成一个固定长度的短向量，所有这些向量就构成一个词向量空间，每一个向量可视为该空间上的一个点。此时向量长度可以自由选择，与词典规模无关。所以方法的核心是上下文的表示以及上下文与目标词之间的关系的建立。

dddd